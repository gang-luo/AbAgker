model:
  base_learning_rate: 1.0e-6
  target: taming.models.model_A2binder.A2binder
  params:
    model_name: AbAg  # PP or AbAg
    frozen_H: True
    frozen_L: True
    frozen_esm2: True
    H_llm: /root/private_data/luog/pretrained_LLM/palm/Heavy_roformer
    L_llm: /root/private_data/luog/pretrained_LLM/palm/Light_roformer
    ems2_llm: /root/private_data/luog/pretrained_LLM/esm2_t30
    ab_maxlen: 512 # max len is 613
    ag_maxlen: 640
    training_evaluate: True
    scheduler_type: None
    # ckpt_path:  /storage/v-jinpewang/experiments/vqocr/logs/2024-09-04T23-38-16_vqgan_model_rendered_text_image_100k_server/checkpoints/last.ckpt
    # ignore_keys: ['loss']
    
    lossconfig:
      target: taming.modules.losses.loss_A2binder.CELoss 
      params:
        # different loss weights
        d_model: 768
        kd_weight: 1.0
        kon_weight: 1.0
        koff_weight: 1.0

data:
  target: main.DataModuleFromConfig
  params:
    batch_size: 4
    num_workers: 4
    train:
      target: taming.data.PM_Data.DataTrain
      params:
        training_list_file: /root/private_data/luog/AbAgker/data/data_1flod/train_7.json
    validation:
      target: taming.data.PM_Data.DataVal
      params:
        val_list_file: /root/private_data/luog/AbAgker/data/data_1flod/test_3.json



