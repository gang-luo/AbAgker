{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data=[\n",
    "    {\n",
    "        \"mol\": \"NS(=O)(=O)c1cc2ccccc2o1\",\n",
    "        \"protein\": \"HHWGYGKHNGPEHWHKDFPIAKGERQSPVDIDTHTAKYDPSLKPLSVSYDQATSLRILNNGHAFNVEFDDSQDKAVLKGGPLDGTYRLIQFHFHWGSLDGQGSEHTVDKKKYAAELHLVHWNTKYGDFGKAVQQPDGLAVLGIFLKVGSAKPGLQKVVDVLDSIKTKGKSADFTNFDPRGLLPESLDYWTYPGSLTTPPLLECVTWIVLKEPISVSSEQVLKFRKLNFNGEGEPEELMVDNWRPAQPLKNRQIKASFK\",\n",
    "        \"text\": 8.64,\n",
    "        \"pocket\": \"Q90,H92,H94,E104,H117,V119,F128,V140,S194,L195,T196,T197,P198,P199,L200,W206\",\n",
    "        \"pdb_code\": \"3s71\",\n",
    "        \"resolution\": \"1.25\",\n",
    "        \"release_year\": 2011,\n",
    "        \"binding_info\": \"Kd=2.3nM\",\n",
    "        \"ligand_name\": \"EVD\"\n",
    "    },\n",
    "    {\n",
    "        \"mol\": \"Cc1nnc(N2CCN(c3ncnc4sc(CC(F)(F)F)cc34)CC2)s1\",\n",
    "        \"protein\": \"GLKAAQKTLFPLRSIDDVVRLFAAELGREEPDLVLLSLVLGFVEHFLAVNRVGLTYFPVADLSIIAALYARFTAQIRGAVDLSLYPREGGVSSRELVKKVSDVIWNSLSRSYFKDRAHIQSLFSFITGTKLDSSGVAFAVVGACQALGLRDVHLALSEDHAWVVFGPNGEQTAEVTWHGKGNEDRRGQTVNAGVAERSWLYLKGSYMRCDRKMEVAFMVCAINPSIDLHTDSLELLQLQQKLLWLLYDLGHLERYPMALGNLADLEELEPTPGRPDPLTLYHKGIASAKTYYRDEHIYPYMYLAGYHCRNRNVREALQAWADTATVIQDYNYCREDEEIYKEFFEVANDVIPNLLKEAASLLEAGSQGSALQDPECFAHLLRFYDGICKWEEGSPTPVLHVGWATFLVQSLGRFEGQVRQKVRIVSPVLTFQSEKMKGMKELLVATKINSSAIKLQLTAQSQVQMKK\",\n",
    "        \"text\": 6.11,\n",
    "        \"pocket\": \"S133,S134,L156,S157,E158,D159,H160,A161,F217,C220,Y255,M257,A258,N261,D264,Y298,M301,Y302\",\n",
    "        \"pdb_code\": \"5dd9\",\n",
    "        \"resolution\": \"1.62\",\n",
    "        \"release_year\": 2015,\n",
    "        \"binding_info\": \"IC50=779nM\",\n",
    "        \"ligand_name\": \"59K\"\n",
    "    },\n",
    "    {\n",
    "        \"mol\": \"O=C(N[C@H]1CC[N@H+](Cc2ccccc2)CC1)c1ccc(I)cc1\",\n",
    "        \"protein\": \"QWAVGRRWAWAALLLAVAAVLTQVVWLWLGTQSFVFQREEIAQLARQYAGLDHELAFSRLIVELRRLHPGHVLPDEELQWVFVNAGGWMGAMCLLHASLSEYVLLFGTALGSRGHSGRYWAEISDTIISGTFHQWREGTTKSEVFYPGETVVHGPGEATAVEWGPNTWMVEYGRGVIPSTLAFALADTVFSTQDFLTLFYTLRSYARGLRLELTTYL\",\n",
    "        \"text\": 8.59,\n",
    "        \"pocket\": \"V83,W88,M92,L94,A97,Y102,L104,F106,S116,Y119,I123,D125,F132,H153,V161,W163,E171,I177,T180,L181,A184,T201,Y205\",\n",
    "        \"pdb_code\": \"5hk2\",\n",
    "        \"resolution\": \"3.20\",\n",
    "        \"release_year\": 2016,\n",
    "        \"binding_info\": \"Ki=2.6nM\",\n",
    "        \"ligand_name\": \"61V\"\n",
    "    }]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.chdir(\"/data01/luog/pmllm\")\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from taming.models.model_pmllm_v4 import PmllmModel\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda:5\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def load_config(config_path, display=False):\n",
    "  config = OmegaConf.load(config_path)\n",
    "  if display:\n",
    "    print(yaml.dump(OmegaConf.to_container(config)))\n",
    "  return config\n",
    "\n",
    "def load_model(config, ckpt_path=None):\n",
    "    model = PmllmModel(**config.model.params)\n",
    "    if ckpt_path is not None:\n",
    "        model.init_from_ckpt(ckpt_path)\n",
    "    return model.eval()\n",
    "\n",
    "\n",
    "config_path=\"/data01/luog/pmllm/config/pmllm_pocket/DTA/Pocket_v4_bert_large_esm2_molformer.yaml\"\n",
    "ckpt_path=\"/data01/luog/pmllm/logs/2024-12-22T09-59-43_Pocket_v4_bert_large_esm2_molformer/checkpoints/last.ckpt\"\n",
    "\n",
    "config=load_config(config_path)\n",
    "model=load_model(config, ckpt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p=[i[\"protein\"] for i in data]\n",
    "m=[i[\"mol\"] for i in data]\n",
    "t=[i[\"text\"] for i in data]\n",
    "pocket=[]\n",
    "for x in data:\n",
    "    pocket.append([i[1:] for i in x[\"pocket\"].split(\",\")])\n",
    "\n",
    "model.training_mask=2\n",
    "outputs_pm, y_m, text_pre, t_loss, pocket = model(p,m,t,pocket)\n",
    "print(model.training_mask)\n",
    "p_probs, m_probs  = model.loss.pm_decoder(outputs_pm) \n",
    "\n",
    "m_labels = y_m.reshape(-1) # 分子SMILES label\n",
    "m_pre = m_probs.argmax(dim=-1).reshape(-1)\n",
    "\n",
    "p_labels = pocket.reshape(-1) # 口袋残基token\n",
    "p_pre = p_probs.argmax(dim=-1).reshape(-1)\n",
    "\n",
    "print(\"m_labels\",m_labels)\n",
    "print(\"m_pre\",m_pre)\n",
    "print(\"p_labels\",p_labels)\n",
    "print(\"p_pre\",p_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_file = \"/root/private_data/luog/AbAgker/data/origin_json/skempi_v2_ed.json\"\n",
    "Kd_all=[]\n",
    "pdb=[]\n",
    "\n",
    "with open(input_file,\"r\") as f:\n",
    "    nums_i=json.load(f)\n",
    "    for i in nums_i:\n",
    "        if len(i[\"seqs\"])==2 and i[\"kd\"]!=\"\": \n",
    "            Kd_all.append(i)\n",
    "            if i[\"pdb\"] not in pdb:\n",
    "                pdb.append(i[\"pdb\"])\n",
    "\n",
    "print(len(Kd_all))\n",
    "print(len(Kd_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoFormerModel(\n",
      "  (embeddings): RoFormerEmbeddings(\n",
      "    (word_embeddings): Embedding(25, 768, padding_idx=20)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): RoFormerEncoder(\n",
      "    (embed_positions): RoFormerSinusoidalPositionalEmbedding(512, 64)\n",
      "    (layer): ModuleList(\n",
      "      (0): RoFormerLayer(\n",
      "        (attention): RoFormerAttention(\n",
      "          (self): RoFormerSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RoFormerSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RoFormerIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RoFormerOutput(\n",
      "          (dense): Linear(in_features=1536, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): RoFormerLayer(\n",
      "        (attention): RoFormerAttention(\n",
      "          (self): RoFormerSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RoFormerSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RoFormerIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RoFormerOutput(\n",
      "          (dense): Linear(in_features=1536, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): RoFormerLayer(\n",
      "        (attention): RoFormerAttention(\n",
      "          (self): RoFormerSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RoFormerSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RoFormerIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RoFormerOutput(\n",
      "          (dense): Linear(in_features=1536, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): RoFormerLayer(\n",
      "        (attention): RoFormerAttention(\n",
      "          (self): RoFormerSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RoFormerSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RoFormerIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RoFormerOutput(\n",
      "          (dense): Linear(in_features=1536, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): RoFormerLayer(\n",
      "        (attention): RoFormerAttention(\n",
      "          (self): RoFormerSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RoFormerSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RoFormerIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RoFormerOutput(\n",
      "          (dense): Linear(in_features=1536, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): RoFormerLayer(\n",
      "        (attention): RoFormerAttention(\n",
      "          (self): RoFormerSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RoFormerSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RoFormerIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RoFormerOutput(\n",
      "          (dense): Linear(in_features=1536, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): RoFormerLayer(\n",
      "        (attention): RoFormerAttention(\n",
      "          (self): RoFormerSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RoFormerSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RoFormerIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RoFormerOutput(\n",
      "          (dense): Linear(in_features=1536, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): RoFormerLayer(\n",
      "        (attention): RoFormerAttention(\n",
      "          (self): RoFormerSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RoFormerSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RoFormerIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RoFormerOutput(\n",
      "          (dense): Linear(in_features=1536, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): RoFormerLayer(\n",
      "        (attention): RoFormerAttention(\n",
      "          (self): RoFormerSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RoFormerSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RoFormerIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RoFormerOutput(\n",
      "          (dense): Linear(in_features=1536, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): RoFormerLayer(\n",
      "        (attention): RoFormerAttention(\n",
      "          (self): RoFormerSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RoFormerSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RoFormerIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RoFormerOutput(\n",
      "          (dense): Linear(in_features=1536, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): RoFormerLayer(\n",
      "        (attention): RoFormerAttention(\n",
      "          (self): RoFormerSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RoFormerSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RoFormerIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RoFormerOutput(\n",
      "          (dense): Linear(in_features=1536, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): RoFormerLayer(\n",
      "        (attention): RoFormerAttention(\n",
      "          (self): RoFormerSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RoFormerSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RoFormerIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RoFormerOutput(\n",
      "          (dense): Linear(in_features=1536, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoConfig\n",
    "\n",
    "# 指定模型的路径\n",
    "model_path = '/root/private_data/luog/pretrained_LLM/palm/A2binder_affinity/lightmodel'\n",
    "\n",
    "# 从 config.json 文件中加载模型配置\n",
    "config = AutoConfig.from_pretrained(model_path)\n",
    "\n",
    "# 从 pytorch_model.bin 文件中加载预训练模型\n",
    "model = AutoModel.from_pretrained(model_path, config=config)\n",
    "\n",
    "# 打印模型结构\n",
    "print(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
